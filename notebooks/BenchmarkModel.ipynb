{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Two stage problem. **\n",
    "* Default Classifier: Use AUC or F1-score to evaluate performance because of class imbalance.\n",
    "* Default Loss: Use MAE ( Evaluation metric ) to evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "basepath = os.path.expanduser('~/Desktop/src/Loan_Default_Prediction/')\n",
    "sys.path.append(os.path.join(basepath, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train  = pd.read_csv(os.path.join(basepath, 'data/raw/train_v2.csv'),\n",
    "                     index_col='id',\n",
    "#                      dtype=np.float32\n",
    "                    )\n",
    "# test   = pd.read_csv(os.path.join(basepath, 'data/raw/test_v2.csv'), index_col='id')\n",
    "# sample_sub = pd.read_csv(os.path.join(basepath, 'data/raw/sampleSubmission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loss target\n",
    "train['is_loss'] = (train.loss > 0).astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Training examples are in the chronological order but not in the test set. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.iloc[np.random.permutation(len(train))] # shuffle training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features to remove from training set\n",
    "features_to_remove = ['f33', 'f678', 'f37', 'f764', 'f700', \\\n",
    "                      'f34', 'f38', 'f702', 'f701', 'f736', 'f35', 'loss',\n",
    "                      'is_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Split dataset **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itrain, itest = train_test_split(range(len(train)), test_size=0.3, random_state=10)\n",
    "\n",
    "X_train = train.iloc[itrain][train.columns.drop(features_to_remove)]\n",
    "X_test  = train.iloc[itest][train.columns.drop(features_to_remove)]\n",
    "\n",
    "y_train = train['is_loss'].iloc[itrain]\n",
    "y_test  = train['is_loss'].iloc[itest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Feature Importance ( Gradient Boosting Classifier ) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imputer = Imputer()\n",
    "imputer.fit(X_train)\n",
    "\n",
    "X_train = imputer.transform(X_train)\n",
    "X_test  = imputer.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature f67 (0.006034)\n",
      "2. feature f767 (0.004061)\n",
      "3. feature f3 (0.003396)\n",
      "4. feature f670 (0.003368)\n",
      "5. feature f746 (0.003209)\n",
      "6. feature f766 (0.003162)\n",
      "7. feature f76 (0.002961)\n",
      "8. feature f404 (0.002921)\n",
      "9. feature f412 (0.002916)\n",
      "10. feature f19 (0.002914)\n",
      "11. feature f468 (0.002881)\n",
      "12. feature f533 (0.002879)\n",
      "13. feature f514 (0.002865)\n",
      "14. feature f212 (0.002854)\n",
      "15. feature f696 (0.002853)\n",
      "16. feature f655 (0.002817)\n",
      "17. feature f75 (0.002799)\n",
      "18. feature f639 (0.002712)\n",
      "19. feature f406 (0.002695)\n",
      "20. feature f413 (0.002681)\n",
      "21. feature f601 (0.002678)\n",
      "22. feature f672 (0.002664)\n",
      "23. feature f774 (0.002660)\n",
      "24. feature f281 (0.002607)\n",
      "25. feature f211 (0.002589)\n",
      "26. feature f322 (0.002581)\n",
      "27. feature f271 (0.002569)\n",
      "28. feature f727 (0.002564)\n",
      "29. feature f479 (0.002550)\n",
      "30. feature f598 (0.002542)\n",
      "31. feature f201 (0.002534)\n",
      "32. feature f149 (0.002518)\n",
      "33. feature f647 (0.002518)\n",
      "34. feature f471 (0.002492)\n",
      "35. feature f402 (0.002484)\n",
      "36. feature f525 (0.002478)\n",
      "37. feature f432 (0.002471)\n",
      "38. feature f673 (0.002449)\n",
      "39. feature f143 (0.002449)\n",
      "40. feature f596 (0.002441)\n",
      "41. feature f671 (0.002419)\n",
      "42. feature f775 (0.002409)\n",
      "43. feature f59 (0.002407)\n",
      "44. feature f431 (0.002403)\n",
      "45. feature f9 (0.002403)\n",
      "46. feature f422 (0.002399)\n",
      "47. feature f613 (0.002391)\n",
      "48. feature f384 (0.002388)\n",
      "49. feature f637 (0.002379)\n",
      "50. feature f740 (0.002368)\n",
      "51. feature f739 (0.002354)\n",
      "52. feature f142 (0.002350)\n",
      "53. feature f638 (0.002348)\n",
      "54. feature f64 (0.002304)\n",
      "55. feature f60 (0.002273)\n",
      "56. feature f16 (0.002265)\n",
      "57. feature f373 (0.002261)\n",
      "58. feature f21 (0.002259)\n",
      "59. feature f518 (0.002255)\n",
      "60. feature f737 (0.002253)\n",
      "61. feature f144 (0.002248)\n",
      "62. feature f674 (0.002246)\n",
      "63. feature f658 (0.002240)\n",
      "64. feature f433 (0.002238)\n",
      "65. feature f522 (0.002236)\n",
      "66. feature f641 (0.002228)\n",
      "67. feature f132 (0.002220)\n",
      "68. feature f26 (0.002204)\n",
      "69. feature f71 (0.002198)\n",
      "70. feature f272 (0.002197)\n",
      "71. feature f218 (0.002176)\n",
      "72. feature f360 (0.002172)\n",
      "73. feature f133 (0.002162)\n",
      "74. feature f600 (0.002155)\n",
      "75. feature f367 (0.002142)\n",
      "76. feature f458 (0.002135)\n",
      "77. feature f10 (0.002132)\n",
      "78. feature f191 (0.002123)\n",
      "79. feature f597 (0.002121)\n",
      "80. feature f141 (0.002120)\n",
      "81. feature f405 (0.002120)\n",
      "82. feature f122 (0.002105)\n",
      "83. feature f66 (0.002102)\n",
      "84. feature f640 (0.002101)\n",
      "85. feature f45 (0.002101)\n",
      "86. feature f738 (0.002097)\n",
      "87. feature f424 (0.002096)\n",
      "88. feature f441 (0.002093)\n",
      "89. feature f652 (0.002088)\n",
      "90. feature f760 (0.002084)\n",
      "91. feature f261 (0.002082)\n",
      "92. feature f716 (0.002078)\n",
      "93. feature f203 (0.002078)\n",
      "94. feature f63 (0.002077)\n",
      "95. feature f251 (0.002070)\n",
      "96. feature f366 (0.002070)\n",
      "97. feature f340 (0.002060)\n",
      "98. feature f745 (0.002057)\n",
      "99. feature f280 (0.002047)\n",
      "100. feature f654 (0.002042)\n",
      "101. feature f614 (0.002041)\n",
      "102. feature f44 (0.002039)\n",
      "103. feature f657 (0.002034)\n",
      "104. feature f629 (0.002007)\n",
      "105. feature f659 (0.001998)\n",
      "106. feature f208 (0.001994)\n",
      "107. feature f660 (0.001991)\n",
      "108. feature f278 (0.001990)\n",
      "109. feature f39 (0.001982)\n",
      "110. feature f57 (0.001979)\n",
      "111. feature f646 (0.001973)\n",
      "112. feature f516 (0.001973)\n",
      "113. feature f612 (0.001966)\n",
      "114. feature f54 (0.001965)\n",
      "115. feature f448 (0.001957)\n",
      "116. feature f339 (0.001953)\n",
      "117. feature f385 (0.001952)\n",
      "118. feature f169 (0.001951)\n",
      "119. feature f444 (0.001942)\n",
      "120. feature f289 (0.001940)\n",
      "121. feature f743 (0.001939)\n",
      "122. feature f628 (0.001931)\n",
      "123. feature f662 (0.001930)\n",
      "124. feature f72 (0.001926)\n",
      "125. feature f645 (0.001923)\n",
      "126. feature f55 (0.001919)\n",
      "127. feature f513 (0.001918)\n",
      "128. feature f230 (0.001917)\n",
      "129. feature f210 (0.001917)\n",
      "130. feature f765 (0.001913)\n",
      "131. feature f70 (0.001903)\n",
      "132. feature f361 (0.001903)\n",
      "133. feature f635 (0.001903)\n",
      "134. feature f609 (0.001903)\n",
      "135. feature f399 (0.001902)\n",
      "136. feature f199 (0.001894)\n",
      "137. feature f393 (0.001889)\n",
      "138. feature f282 (0.001883)\n",
      "139. feature f376 (0.001879)\n",
      "140. feature f631 (0.001873)\n",
      "141. feature f374 (0.001872)\n",
      "142. feature f213 (0.001872)\n",
      "143. feature f425 (0.001871)\n",
      "144. feature f148 (0.001870)\n",
      "145. feature f102 (0.001865)\n",
      "146. feature f49 (0.001865)\n",
      "147. feature f756 (0.001864)\n",
      "148. feature f588 (0.001862)\n",
      "149. feature f161 (0.001861)\n",
      "150. feature f734 (0.001861)\n",
      "151. feature f623 (0.001858)\n",
      "152. feature f160 (0.001857)\n",
      "153. feature f593 (0.001854)\n",
      "154. feature f68 (0.001854)\n",
      "155. feature f273 (0.001853)\n",
      "156. feature f536 (0.001850)\n",
      "157. feature f140 (0.001845)\n",
      "158. feature f618 (0.001845)\n",
      "159. feature f170 (0.001845)\n",
      "160. feature f279 (0.001839)\n",
      "161. feature f434 (0.001839)\n",
      "162. feature f50 (0.001837)\n",
      "163. feature f334 (0.001834)\n",
      "164. feature f383 (0.001832)\n",
      "165. feature f349 (0.001828)\n",
      "166. feature f32 (0.001825)\n",
      "167. feature f202 (0.001824)\n",
      "168. feature f649 (0.001819)\n",
      "169. feature f249 (0.001817)\n",
      "170. feature f25 (0.001812)\n",
      "171. feature f359 (0.001809)\n",
      "172. feature f229 (0.001805)\n",
      "173. feature f179 (0.001801)\n",
      "174. feature f209 (0.001797)\n",
      "175. feature f134 (0.001792)\n",
      "176. feature f147 (0.001792)\n",
      "177. feature f47 (0.001791)\n",
      "178. feature f499 (0.001781)\n",
      "179. feature f46 (0.001780)\n",
      "180. feature f387 (0.001779)\n",
      "181. feature f200 (0.001773)\n",
      "182. feature f358 (0.001769)\n",
      "183. feature f69 (0.001765)\n",
      "184. feature f1 (0.001764)\n",
      "185. feature f416 (0.001760)\n",
      "186. feature f664 (0.001758)\n",
      "187. feature f145 (0.001738)\n",
      "188. feature f350 (0.001732)\n",
      "189. feature f763 (0.001725)\n",
      "190. feature f331 (0.001725)\n",
      "191. feature f443 (0.001723)\n",
      "192. feature f369 (0.001722)\n",
      "193. feature f22 (0.001717)\n",
      "194. feature f183 (0.001712)\n",
      "195. feature f676 (0.001710)\n",
      "196. feature f442 (0.001710)\n",
      "197. feature f353 (0.001709)\n",
      "198. feature f401 (0.001708)\n",
      "199. feature f388 (0.001701)\n",
      "200. feature f450 (0.001694)\n",
      "201. feature f6 (0.001694)\n",
      "202. feature f768 (0.001692)\n",
      "203. feature f17 (0.001686)\n",
      "204. feature f410 (0.001685)\n",
      "205. feature f436 (0.001679)\n",
      "206. feature f667 (0.001678)\n",
      "207. feature f56 (0.001676)\n",
      "208. feature f411 (0.001675)\n",
      "209. feature f341 (0.001671)\n",
      "210. feature f146 (0.001671)\n",
      "211. feature f440 (0.001671)\n",
      "212. feature f489 (0.001670)\n",
      "213. feature f599 (0.001669)\n",
      "214. feature f400 (0.001666)\n",
      "215. feature f509 (0.001664)\n",
      "216. feature f61 (0.001663)\n",
      "217. feature f643 (0.001663)\n",
      "218. feature f517 (0.001659)\n",
      "219. feature f669 (0.001657)\n",
      "220. feature f14 (0.001657)\n",
      "221. feature f333 (0.001655)\n",
      "222. feature f315 (0.001652)\n",
      "223. feature f663 (0.001644)\n",
      "224. feature f726 (0.001642)\n",
      "225. feature f733 (0.001640)\n",
      "226. feature f526 (0.001640)\n",
      "227. feature f30 (0.001639)\n",
      "228. feature f283 (0.001636)\n",
      "229. feature f186 (0.001634)\n",
      "230. feature f112 (0.001633)\n",
      "231. feature f626 (0.001629)\n",
      "232. feature f77 (0.001625)\n",
      "233. feature f13 (0.001623)\n",
      "234. feature f250 (0.001623)\n",
      "235. feature f356 (0.001622)\n",
      "236. feature f377 (0.001607)\n",
      "237. feature f524 (0.001603)\n",
      "238. feature f378 (0.001602)\n",
      "239. feature f365 (0.001601)\n",
      "240. feature f648 (0.001594)\n",
      "241. feature f624 (0.001593)\n",
      "242. feature f611 (0.001592)\n",
      "243. feature f398 (0.001591)\n",
      "244. feature f51 (0.001586)\n",
      "245. feature f642 (0.001585)\n",
      "246. feature f65 (0.001585)\n",
      "247. feature f392 (0.001580)\n",
      "248. feature f650 (0.001577)\n",
      "249. feature f682 (0.001573)\n",
      "250. feature f375 (0.001573)\n",
      "251. feature f430 (0.001572)\n",
      "252. feature f330 (0.001570)\n",
      "253. feature f429 (0.001569)\n",
      "254. feature f634 (0.001562)\n",
      "255. feature f418 (0.001562)\n",
      "256. feature f627 (0.001558)\n",
      "257. feature f23 (0.001557)\n",
      "258. feature f653 (0.001556)\n",
      "259. feature f352 (0.001552)\n",
      "260. feature f171 (0.001549)\n",
      "261. feature f189 (0.001547)\n",
      "262. feature f336 (0.001542)\n",
      "263. feature f221 (0.001541)\n",
      "264. feature f347 (0.001533)\n",
      "265. feature f357 (0.001533)\n",
      "266. feature f150 (0.001531)\n",
      "267. feature f348 (0.001529)\n",
      "268. feature f390 (0.001528)\n",
      "269. feature f636 (0.001526)\n",
      "270. feature f586 (0.001524)\n",
      "271. feature f742 (0.001520)\n",
      "272. feature f220 (0.001519)\n",
      "273. feature f778 (0.001515)\n",
      "274. feature f168 (0.001510)\n",
      "275. feature f343 (0.001509)\n",
      "276. feature f180 (0.001508)\n",
      "277. feature f435 (0.001503)\n",
      "278. feature f29 (0.001501)\n",
      "279. feature f620 (0.001493)\n",
      "280. feature f153 (0.001491)\n",
      "281. feature f470 (0.001490)\n",
      "282. feature f698 (0.001489)\n",
      "283. feature f351 (0.001480)\n",
      "284. feature f204 (0.001479)\n",
      "285. feature f751 (0.001474)\n",
      "286. feature f15 (0.001467)\n",
      "287. feature f697 (0.001459)\n",
      "288. feature f619 (0.001459)\n",
      "289. feature f630 (0.001458)\n",
      "290. feature f286 (0.001448)\n",
      "291. feature f370 (0.001445)\n",
      "292. feature f621 (0.001445)\n",
      "293. feature f159 (0.001440)\n",
      "294. feature f31 (0.001439)\n",
      "295. feature f288 (0.001434)\n",
      "296. feature f466 (0.001430)\n",
      "297. feature f409 (0.001428)\n",
      "298. feature f53 (0.001427)\n",
      "299. feature f423 (0.001427)\n",
      "300. feature f80 (0.001425)\n",
      "301. feature f110 (0.001422)\n",
      "302. feature f190 (0.001418)\n",
      "303. feature f610 (0.001417)\n",
      "304. feature f382 (0.001413)\n",
      "305. feature f306 (0.001413)\n",
      "306. feature f344 (0.001411)\n",
      "307. feature f397 (0.001408)\n",
      "308. feature f505 (0.001406)\n",
      "309. feature f139 (0.001400)\n",
      "310. feature f651 (0.001399)\n",
      "311. feature f622 (0.001399)\n",
      "312. feature f342 (0.001397)\n",
      "313. feature f656 (0.001390)\n",
      "314. feature f285 (0.001389)\n",
      "315. feature f269 (0.001381)\n",
      "316. feature f20 (0.001380)\n",
      "317. feature f40 (0.001379)\n",
      "318. feature f90 (0.001378)\n",
      "319. feature f332 (0.001374)\n",
      "320. feature f275 (0.001373)\n",
      "321. feature f428 (0.001371)\n",
      "322. feature f386 (0.001366)\n",
      "323. feature f426 (0.001364)\n",
      "324. feature f680 (0.001359)\n",
      "325. feature f520 (0.001357)\n",
      "326. feature f260 (0.001357)\n",
      "327. feature f665 (0.001356)\n",
      "328. feature f460 (0.001350)\n",
      "329. feature f41 (0.001346)\n",
      "330. feature f219 (0.001345)\n",
      "331. feature f18 (0.001341)\n",
      "332. feature f695 (0.001338)\n",
      "333. feature f287 (0.001337)\n",
      "334. feature f194 (0.001333)\n",
      "335. feature f346 (0.001326)\n",
      "336. feature f735 (0.001325)\n",
      "337. feature f396 (0.001323)\n",
      "338. feature f668 (0.001317)\n",
      "339. feature f438 (0.001315)\n",
      "340. feature f687 (0.001310)\n",
      "341. feature f661 (0.001307)\n",
      "342. feature f715 (0.001307)\n",
      "343. feature f239 (0.001303)\n",
      "344. feature f216 (0.001299)\n",
      "345. feature f316 (0.001297)\n",
      "346. feature f523 (0.001297)\n",
      "347. feature f421 (0.001291)\n",
      "348. feature f193 (0.001279)\n",
      "349. feature f560 (0.001278)\n",
      "350. feature f368 (0.001273)\n",
      "351. feature f136 (0.001273)\n",
      "352. feature f197 (0.001273)\n",
      "353. feature f732 (0.001269)\n",
      "354. feature f485 (0.001269)\n",
      "355. feature f101 (0.001268)\n",
      "356. feature f731 (0.001258)\n",
      "357. feature f721 (0.001257)\n",
      "358. feature f394 (0.001256)\n",
      "359. feature f771 (0.001253)\n",
      "360. feature f675 (0.001249)\n",
      "361. feature f677 (0.001249)\n",
      "362. feature f590 (0.001249)\n",
      "363. feature f263 (0.001242)\n",
      "364. feature f88 (0.001240)\n",
      "365. feature f175 (0.001239)\n",
      "366. feature f188 (0.001235)\n",
      "367. feature f545 (0.001233)\n",
      "368. feature f92 (0.001232)\n",
      "369. feature f4 (0.001228)\n",
      "370. feature f717 (0.001222)\n",
      "371. feature f173 (0.001221)\n",
      "372. feature f131 (0.001221)\n",
      "373. feature f503 (0.001215)\n",
      "374. feature f163 (0.001215)\n",
      "375. feature f363 (0.001207)\n",
      "376. feature f465 (0.001204)\n",
      "377. feature f196 (0.001202)\n",
      "378. feature f86 (0.001201)\n",
      "379. feature f594 (0.001200)\n",
      "380. feature f744 (0.001200)\n",
      "381. feature f298 (0.001200)\n",
      "382. feature f501 (0.001199)\n",
      "383. feature f154 (0.001196)\n",
      "384. feature f407 (0.001193)\n",
      "385. feature f632 (0.001190)\n",
      "386. feature f43 (0.001188)\n",
      "387. feature f451 (0.001187)\n",
      "388. feature f689 (0.001182)\n",
      "389. feature f607 (0.001180)\n",
      "390. feature f511 (0.001177)\n",
      "391. feature f445 (0.001177)\n",
      "392. feature f100 (0.001174)\n",
      "393. feature f391 (0.001172)\n",
      "394. feature f81 (0.001165)\n",
      "395. feature f380 (0.001165)\n",
      "396. feature f240 (0.001159)\n",
      "397. feature f719 (0.001159)\n",
      "398. feature f570 (0.001159)\n",
      "399. feature f447 (0.001156)\n",
      "400. feature f195 (0.001142)\n",
      "401. feature f178 (0.001141)\n",
      "402. feature f181 (0.001140)\n",
      "403. feature f395 (0.001139)\n",
      "404. feature f562 (0.001138)\n",
      "405. feature f769 (0.001137)\n",
      "406. feature f215 (0.001136)\n",
      "407. feature f185 (0.001135)\n",
      "408. feature f323 (0.001133)\n",
      "409. feature f508 (0.001130)\n",
      "410. feature f573 (0.001130)\n",
      "411. feature f324 (0.001124)\n",
      "412. feature f187 (0.001124)\n",
      "413. feature f117 (0.001122)\n",
      "414. feature f691 (0.001119)\n",
      "415. feature f78 (0.001118)\n",
      "416. feature f217 (0.001116)\n",
      "417. feature f548 (0.001114)\n",
      "418. feature f592 (0.001108)\n",
      "419. feature f415 (0.001107)\n",
      "420. feature f5 (0.001105)\n",
      "421. feature f214 (0.001105)\n",
      "422. feature f537 (0.001105)\n",
      "423. feature f414 (0.001103)\n",
      "424. feature f752 (0.001102)\n",
      "425. feature f469 (0.001099)\n",
      "426. feature f245 (0.001095)\n",
      "427. feature f176 (0.001094)\n",
      "428. feature f205 (0.001094)\n",
      "429. feature f761 (0.001093)\n",
      "430. feature f225 (0.001093)\n",
      "431. feature f91 (0.001089)\n",
      "432. feature f364 (0.001086)\n",
      "433. feature f105 (0.001086)\n",
      "434. feature f79 (0.001085)\n",
      "435. feature f540 (0.001084)\n",
      "436. feature f290 (0.001082)\n",
      "437. feature f174 (0.001078)\n",
      "438. feature f556 (0.001077)\n",
      "439. feature f495 (0.001075)\n",
      "440. feature f685 (0.001067)\n",
      "441. feature f494 (0.001067)\n",
      "442. feature f587 (0.001067)\n",
      "443. feature f728 (0.001058)\n",
      "444. feature f335 (0.001055)\n",
      "445. feature f82 (0.001053)\n",
      "446. feature f305 (0.001052)\n",
      "447. feature f507 (0.001050)\n",
      "448. feature f277 (0.001048)\n",
      "449. feature f591 (0.001046)\n",
      "450. feature f257 (0.001042)\n",
      "451. feature f754 (0.001040)\n",
      "452. feature f276 (0.001036)\n",
      "453. feature f84 (0.001035)\n",
      "454. feature f115 (0.001034)\n",
      "455. feature f118 (0.001031)\n",
      "456. feature f27 (0.001030)\n",
      "457. feature f355 (0.001027)\n",
      "458. feature f381 (0.001026)\n",
      "459. feature f151 (0.001023)\n",
      "460. feature f608 (0.001017)\n",
      "461. feature f24 (0.001016)\n",
      "462. feature f773 (0.001015)\n",
      "463. feature f106 (0.001014)\n",
      "464. feature f165 (0.001014)\n",
      "465. feature f772 (0.001014)\n",
      "466. feature f241 (0.001013)\n",
      "467. feature f99 (0.001010)\n",
      "468. feature f130 (0.001010)\n",
      "469. feature f694 (0.001009)\n",
      "470. feature f259 (0.001009)\n",
      "471. feature f709 (0.001005)\n",
      "472. feature f437 (0.000999)\n",
      "473. feature f135 (0.000998)\n",
      "474. feature f166 (0.000998)\n",
      "475. feature f111 (0.000998)\n",
      "476. feature f483 (0.000998)\n",
      "477. feature f529 (0.000997)\n",
      "478. feature f476 (0.000994)\n",
      "479. feature f712 (0.000993)\n",
      "480. feature f321 (0.000990)\n",
      "481. feature f683 (0.000985)\n",
      "482. feature f714 (0.000985)\n",
      "483. feature f89 (0.000984)\n",
      "484. feature f120 (0.000981)\n",
      "485. feature f561 (0.000981)\n",
      "486. feature f167 (0.000977)\n",
      "487. feature f710 (0.000974)\n",
      "488. feature f164 (0.000970)\n",
      "489. feature f157 (0.000970)\n",
      "490. feature f564 (0.000969)\n",
      "491. feature f284 (0.000969)\n",
      "492. feature f703 (0.000968)\n",
      "493. feature f28 (0.000966)\n",
      "494. feature f711 (0.000964)\n",
      "495. feature f236 (0.000964)\n",
      "496. feature f530 (0.000962)\n",
      "497. feature f7 (0.000960)\n",
      "498. feature f419 (0.000954)\n",
      "499. feature f97 (0.000952)\n",
      "500. feature f693 (0.000951)\n",
      "501. feature f449 (0.000948)\n",
      "502. feature f439 (0.000948)\n",
      "503. feature f155 (0.000947)\n",
      "504. feature f308 (0.000945)\n",
      "505. feature f589 (0.000945)\n",
      "506. feature f496 (0.000941)\n",
      "507. feature f486 (0.000941)\n",
      "508. feature f446 (0.000937)\n",
      "509. feature f137 (0.000936)\n",
      "510. feature f454 (0.000936)\n",
      "511. feature f686 (0.000936)\n",
      "512. feature f238 (0.000935)\n",
      "513. feature f247 (0.000935)\n",
      "514. feature f535 (0.000934)\n",
      "515. feature f158 (0.000934)\n",
      "516. feature f568 (0.000933)\n",
      "517. feature f223 (0.000927)\n",
      "518. feature f121 (0.000926)\n",
      "519. feature f222 (0.000924)\n",
      "520. feature f725 (0.000924)\n",
      "521. feature f138 (0.000923)\n",
      "522. feature f519 (0.000921)\n",
      "523. feature f314 (0.000919)\n",
      "524. feature f184 (0.000917)\n",
      "525. feature f177 (0.000917)\n",
      "526. feature f123 (0.000916)\n",
      "527. feature f85 (0.000914)\n",
      "528. feature f581 (0.000914)\n",
      "529. feature f192 (0.000913)\n",
      "530. feature f227 (0.000912)\n",
      "531. feature f708 (0.000909)\n",
      "532. feature f246 (0.000909)\n",
      "533. feature f127 (0.000907)\n",
      "534. feature f504 (0.000904)\n",
      "535. feature f758 (0.000904)\n",
      "536. feature f558 (0.000904)\n",
      "537. feature f577 (0.000901)\n",
      "538. feature f750 (0.000901)\n",
      "539. feature f552 (0.000901)\n",
      "540. feature f755 (0.000901)\n",
      "541. feature f455 (0.000900)\n",
      "542. feature f521 (0.000898)\n",
      "543. feature f182 (0.000898)\n",
      "544. feature f546 (0.000895)\n",
      "545. feature f572 (0.000891)\n",
      "546. feature f87 (0.000891)\n",
      "547. feature f464 (0.000890)\n",
      "548. feature f749 (0.000889)\n",
      "549. feature f549 (0.000888)\n",
      "550. feature f156 (0.000880)\n",
      "551. feature f705 (0.000874)\n",
      "552. feature f684 (0.000872)\n",
      "553. feature f515 (0.000866)\n",
      "554. feature f8 (0.000865)\n",
      "555. feature f498 (0.000862)\n",
      "556. feature f206 (0.000859)\n",
      "557. feature f730 (0.000856)\n",
      "558. feature f757 (0.000853)\n",
      "559. feature f372 (0.000852)\n",
      "560. feature f538 (0.000850)\n",
      "561. feature f457 (0.000850)\n",
      "562. feature f467 (0.000844)\n",
      "563. feature f231 (0.000840)\n",
      "564. feature f265 (0.000837)\n",
      "565. feature f688 (0.000836)\n",
      "566. feature f493 (0.000835)\n",
      "567. feature f759 (0.000835)\n",
      "568. feature f606 (0.000833)\n",
      "569. feature f762 (0.000832)\n",
      "570. feature f718 (0.000831)\n",
      "571. feature f452 (0.000830)\n",
      "572. feature f274 (0.000827)\n",
      "573. feature f500 (0.000827)\n",
      "574. feature f753 (0.000823)\n",
      "575. feature f706 (0.000822)\n",
      "576. feature f300 (0.000822)\n",
      "577. feature f528 (0.000822)\n",
      "578. feature f583 (0.000819)\n",
      "579. feature f109 (0.000816)\n",
      "580. feature f510 (0.000815)\n",
      "581. feature f566 (0.000814)\n",
      "582. feature f699 (0.000814)\n",
      "583. feature f481 (0.000813)\n",
      "584. feature f531 (0.000810)\n",
      "585. feature f234 (0.000807)\n",
      "586. feature f83 (0.000806)\n",
      "587. feature f704 (0.000804)\n",
      "588. feature f266 (0.000804)\n",
      "589. feature f487 (0.000800)\n",
      "590. feature f553 (0.000799)\n",
      "591. feature f748 (0.000799)\n",
      "592. feature f666 (0.000794)\n",
      "593. feature f124 (0.000792)\n",
      "594. feature f550 (0.000792)\n",
      "595. feature f242 (0.000791)\n",
      "596. feature f555 (0.000791)\n",
      "597. feature f512 (0.000789)\n",
      "598. feature f313 (0.000789)\n",
      "599. feature f107 (0.000786)\n",
      "600. feature f270 (0.000784)\n",
      "601. feature f527 (0.000773)\n",
      "602. feature f547 (0.000768)\n",
      "603. feature f579 (0.000767)\n",
      "604. feature f116 (0.000765)\n",
      "605. feature f319 (0.000765)\n",
      "606. feature f541 (0.000763)\n",
      "607. feature f232 (0.000763)\n",
      "608. feature f478 (0.000760)\n",
      "609. feature f103 (0.000760)\n",
      "610. feature f559 (0.000757)\n",
      "611. feature f484 (0.000756)\n",
      "612. feature f617 (0.000755)\n",
      "613. feature f253 (0.000753)\n",
      "614. feature f262 (0.000753)\n",
      "615. feature f268 (0.000753)\n",
      "616. feature f58 (0.000748)\n",
      "617. feature f542 (0.000748)\n",
      "618. feature f226 (0.000744)\n",
      "619. feature f389 (0.000739)\n",
      "620. feature f228 (0.000738)\n",
      "621. feature f198 (0.000737)\n",
      "622. feature f707 (0.000734)\n",
      "623. feature f2 (0.000734)\n",
      "624. feature f337 (0.000734)\n",
      "625. feature f543 (0.000733)\n",
      "626. feature f461 (0.000733)\n",
      "627. feature f477 (0.000731)\n",
      "628. feature f585 (0.000730)\n",
      "629. feature f267 (0.000727)\n",
      "630. feature f318 (0.000726)\n",
      "631. feature f459 (0.000723)\n",
      "632. feature f502 (0.000722)\n",
      "633. feature f95 (0.000721)\n",
      "634. feature f567 (0.000719)\n",
      "635. feature f248 (0.000719)\n",
      "636. feature f584 (0.000719)\n",
      "637. feature f720 (0.000717)\n",
      "638. feature f551 (0.000716)\n",
      "639. feature f539 (0.000714)\n",
      "640. feature f544 (0.000711)\n",
      "641. feature f582 (0.000709)\n",
      "642. feature f296 (0.000702)\n",
      "643. feature f235 (0.000702)\n",
      "644. feature f578 (0.000701)\n",
      "645. feature f497 (0.000697)\n",
      "646. feature f569 (0.000696)\n",
      "647. feature f114 (0.000695)\n",
      "648. feature f475 (0.000694)\n",
      "649. feature f244 (0.000693)\n",
      "650. feature f563 (0.000692)\n",
      "651. feature f747 (0.000692)\n",
      "652. feature f690 (0.000688)\n",
      "653. feature f456 (0.000687)\n",
      "654. feature f625 (0.000683)\n",
      "655. feature f491 (0.000681)\n",
      "656. feature f293 (0.000674)\n",
      "657. feature f488 (0.000668)\n",
      "658. feature f534 (0.000667)\n",
      "659. feature f224 (0.000658)\n",
      "660. feature f565 (0.000658)\n",
      "661. feature f403 (0.000657)\n",
      "662. feature f557 (0.000657)\n",
      "663. feature f329 (0.000657)\n",
      "664. feature f729 (0.000655)\n",
      "665. feature f506 (0.000653)\n",
      "666. feature f575 (0.000648)\n",
      "667. feature f243 (0.000645)\n",
      "668. feature f256 (0.000643)\n",
      "669. feature f237 (0.000641)\n",
      "670. feature f294 (0.000640)\n",
      "671. feature f119 (0.000638)\n",
      "672. feature f679 (0.000636)\n",
      "673. feature f292 (0.000636)\n",
      "674. feature f299 (0.000634)\n",
      "675. feature f264 (0.000626)\n",
      "676. feature f571 (0.000622)\n",
      "677. feature f692 (0.000618)\n",
      "678. feature f482 (0.000616)\n",
      "679. feature f258 (0.000614)\n",
      "680. feature f312 (0.000614)\n",
      "681. feature f104 (0.000602)\n",
      "682. feature f125 (0.000599)\n",
      "683. feature f408 (0.000596)\n",
      "684. feature f302 (0.000590)\n",
      "685. feature f172 (0.000587)\n",
      "686. feature f580 (0.000586)\n",
      "687. feature f532 (0.000586)\n",
      "688. feature f126 (0.000586)\n",
      "689. feature f62 (0.000584)\n",
      "690. feature f307 (0.000578)\n",
      "691. feature f309 (0.000577)\n",
      "692. feature f311 (0.000576)\n",
      "693. feature f472 (0.000576)\n",
      "694. feature f301 (0.000569)\n",
      "695. feature f770 (0.000567)\n",
      "696. feature f108 (0.000563)\n",
      "697. feature f113 (0.000562)\n",
      "698. feature f252 (0.000561)\n",
      "699. feature f233 (0.000561)\n",
      "700. feature f94 (0.000560)\n",
      "701. feature f327 (0.000554)\n",
      "702. feature f128 (0.000547)\n",
      "703. feature f576 (0.000534)\n",
      "704. feature f574 (0.000527)\n",
      "705. feature f492 (0.000526)\n",
      "706. feature f722 (0.000520)\n",
      "707. feature f152 (0.000520)\n",
      "708. feature f320 (0.000517)\n",
      "709. feature f93 (0.000516)\n",
      "710. feature f255 (0.000508)\n",
      "711. feature f96 (0.000506)\n",
      "712. feature f453 (0.000504)\n",
      "713. feature f129 (0.000496)\n",
      "714. feature f162 (0.000496)\n",
      "715. feature f310 (0.000493)\n",
      "716. feature f345 (0.000490)\n",
      "717. feature f328 (0.000485)\n",
      "718. feature f297 (0.000483)\n",
      "719. feature f633 (0.000477)\n",
      "720. feature f362 (0.000474)\n",
      "721. feature f554 (0.000472)\n",
      "722. feature f317 (0.000471)\n",
      "723. feature f371 (0.000466)\n",
      "724. feature f713 (0.000465)\n",
      "725. feature f207 (0.000462)\n",
      "726. feature f490 (0.000454)\n",
      "727. feature f615 (0.000448)\n",
      "728. feature f254 (0.000445)\n",
      "729. feature f604 (0.000443)\n",
      "730. feature f480 (0.000443)\n",
      "731. feature f417 (0.000438)\n",
      "732. feature f73 (0.000437)\n",
      "733. feature f98 (0.000425)\n",
      "734. feature f325 (0.000420)\n",
      "735. feature f427 (0.000415)\n",
      "736. feature f644 (0.000406)\n",
      "737. feature f304 (0.000404)\n",
      "738. feature f354 (0.000400)\n",
      "739. feature f36 (0.000397)\n",
      "740. feature f616 (0.000381)\n",
      "741. feature f303 (0.000376)\n",
      "742. feature f48 (0.000364)\n",
      "743. feature f74 (0.000354)\n",
      "744. feature f379 (0.000352)\n",
      "745. feature f681 (0.000345)\n",
      "746. feature f42 (0.000342)\n",
      "747. feature f420 (0.000335)\n",
      "748. feature f291 (0.000324)\n",
      "749. feature f295 (0.000312)\n",
      "750. feature f595 (0.000290)\n",
      "751. feature f52 (0.000259)\n",
      "752. feature f741 (0.000258)\n",
      "753. feature f326 (0.000250)\n",
      "754. feature f338 (0.000247)\n",
      "755. feature f723 (0.000174)\n",
      "756. feature f724 (0.000077)\n",
      "757. feature f776 (0.000071)\n",
      "758. feature f777 (0.000043)\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=0, n_jobs=3)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "features = train.columns.drop(features_to_remove)\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, features[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "# plt.figure()\n",
    "# plt.title(\"Feature importances\")\n",
    "# plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "#        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "# plt.xticks(range(X_train.shape[1]), indices, rotation=90)\n",
    "# plt.xlim([-1, X_train.shape[1]])\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Feature Importance (Default Classifier) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xgb_imp(trained_xgb, feature_names):\n",
    "    imp_vals = trained_xgb.booster().get_fscore()\n",
    "    imp_dict = {feature_names[i]:float(imp_vals.get(feature_names[i],0.)) for i in range(len(feature_names))}\n",
    "    \n",
    "    return pd.DataFrame.from_dict(imp_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('imputer', Imputer()),\n",
    "        ('scale', StandardScaler()),\n",
    "        ('model', xgb.XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit on training set\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat_importance = get_xgb_imp(pipeline.get_params()['model'], X_train.columns)\n",
    "sorted_feat_importance = feat_importance.sort_values(by=0, ascending=False)\n",
    "print('Feature Importance ( XGBoost): \\n')\n",
    "print(sorted_feat_importance.iloc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train on features deemed important. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_feat_importance.index[70:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_features = sorted_feat_importance.index[:20]\n",
    "\n",
    "X_train_sub = X_train[selected_features]\n",
    "X_test_sub  = X_test[selected_features]\n",
    "\n",
    "pipeline.fit(X_train_sub, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Test on the held out set. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds_prob = pipeline.predict_proba(X_test_sub)[:, 1]\n",
    "preds      = pipeline.predict(X_test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_test.iloc[10: 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('AUC score: %f'%(roc_auc_score(y_test, preds_prob)))\n",
    "print('F1 score: %f'%(f1_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cv(estimators, X, y):\n",
    "    skf = StratifiedKFold(y, n_folds=3, shuffle=True, random_state=12)\n",
    "    best_estimators = [] # list of best estimators \n",
    "    scores = [] # mae score for every fold\n",
    "    \n",
    "    for itrain, itest in skf:\n",
    "        Xtr = X[itrain]\n",
    "        Xte = X[itest]\n",
    "        \n",
    "        ytr = y[itrain]\n",
    "        yte = y[itest]\n",
    "        \n",
    "        min_score = np.Infinity\n",
    "        \n",
    "        for est in estimators:\n",
    "            est.fit(Xtr, ytr)\n",
    "            pred = est.predict(Xte)\n",
    "            score = mean_absolute_error(yte, pred)\n",
    "            \n",
    "            if score < min_score:\n",
    "                min_score      = score\n",
    "                best_estimator = est\n",
    "        \n",
    "        best_estimators.append(best_estimator)\n",
    "        scores.append(min_score)\n",
    "    \n",
    "    return best_estimators, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline_rf = Pipeline([\n",
    "        ('imputer', Imputer()),\n",
    "        ('select', SelectKBest(f_regression, k=100)),\n",
    "        ('model', RandomForestRegressor(random_state=3, n_jobs=3))\n",
    "    ])\n",
    "\n",
    "pipeline_linear = Pipeline([\n",
    "        ('imputer', Imputer()),\n",
    "        ('scale', StandardScaler()),\n",
    "        ('select', SelectKBest(f_regression, k=100)),\n",
    "        ('model', Lasso(random_state=3))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_ests, scores = cv([pipeline_linear, pipeline_rf, pipeline_gbr], X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_ests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test on the held out examples\n",
    "best_ests[0].fit(X_train, y_train)\n",
    "print('MAE Random Forest Regressor ', mean_absolute_error(y_test, best_ests[0].predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_ests[1].fit(X_train, y_train)\n",
    "print('MAE Lasso Regression ', mean_absolute_error(y_test, best_ests[1].predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train on the full dataset\n",
    "best_ests[2].fit(train, target)\n",
    "loss = pipeline_linear.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv(os.path.join(basepath, 'data/raw/sampleSubmission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_sub['loss'] = loss\n",
    "sample_sub.to_csv(os.path.join(basepath, 'submissions/baseline.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
