{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Objectives **\n",
    "\n",
    "* How to load a large file into memory using Pandas ?\n",
    "* How to take a representative sample from a population ?\n",
    "    * Stratified sample\n",
    "* Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "basepath = os.path.expanduser('~/Desktop/src/Loan_Default_Prediction/')\n",
    "sys.path.append(os.path.join(basepath, 'src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Stratified Sample **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stratified_sample(X, y, train_size, random_state=10):\n",
    "    \"\"\"\n",
    "    Takes in a feature set and target with percentage of training size and a seed for reproducability.\n",
    "    Returns indices for the training and test sets.\n",
    "    \"\"\"\n",
    "    \n",
    "    itrain, itest = train_test_split(range(len(X)), stratify=y, train_size=train_size, random_state=random_state)\n",
    "    return itrain, itest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load files\n",
    "chunksize = 10 ** 4\n",
    "\n",
    "train_chunks = pd.read_table(os.path.join(basepath, 'data/raw/train_v2.csv'), \\\n",
    "                             chunksize=chunksize, \\\n",
    "                             sep=',', \\\n",
    "                             index_col='id'\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.concat(train_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a binary variable based on the target\n",
    "train['is_default'] = (train.loss > 0).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itrain, itest = get_stratified_sample(train, train.is_default, 0.4)\n",
    "\n",
    "train_sample = train.iloc[itrain]\n",
    "del train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the sample:  (42188, 771)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the sample: ', (train_sample.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unique_values(df, features):\n",
    "    return {feature: df[feature].nunique() for feature in features}\n",
    "\n",
    "def get_features_std(df):\n",
    "    # select numerical features\n",
    "    numerical_columns = df.select_dtypes(exclude=['object']).columns\n",
    "    \n",
    "    return {col:df[col].std() for col in numerical_columns}\n",
    "        \n",
    "\n",
    "def get_features_with_single_val(feature_dict):\n",
    "    return [k for k, v in feature_dict.items() if v == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = train_sample.columns.drop(['is_default', 'loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_dict_train = unique_values(train_sample, features)\n",
    "# feature_dict_test  = unique_values(test, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_with_single_val_train = get_features_with_single_val(feature_dict_train)\n",
    "# features_with_single_val_test  = get_features_with_single_val(feature_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_std_train = get_features_std(train_sample)\n",
    "# features_std_test  = get_features_std(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Features in training set which take a single value. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(features_with_single_val_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Features in the training set which have zero standard deviation. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(filter(lambda x: features_std_train[x] == 0, features_std_train.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Histogram of features ( training set ) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_index = 760\n",
    "end_index   = 770\n",
    "\n",
    "train_sample.ix[:, start_index:end_index].hist(figsize=(16, 12), bins=50)\n",
    "plt.savefig(os.path.join(basepath, 'reports/figures/feat_%s-%s'%(start_index, end_index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Save the histograms to disk so that we can observe the distribution. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Feature Selection **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "itrain, itest = get_stratified_sample(train_sample, train_sample.is_default, train_size=0.7, random_state=11)\n",
    "\n",
    "X_train = train_sample.iloc[itrain][features]\n",
    "X_test  = train_sample.iloc[itest][features]\n",
    "\n",
    "y_train = train_sample.is_default.iloc[itrain]\n",
    "y_test  = train_sample.is_default.iloc[itest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('select', SelectKBest(k=50, score_func=<function f_classif at 0x7f6aee5d3e18>)), ('model', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('imputer', Imputer()),\n",
    "        ('select', SelectKBest(f_classif, k=50)),\n",
    "        ('model', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07361307,  0.100728  ,  0.15715329, ...,  0.09276123,\n",
       "        0.27803367,  0.05966236])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, train, test):\n",
    "        self.train = train\n",
    "        self.test  = test\n",
    "    \n",
    "    def extract(self):\n",
    "        self.round_values()\n",
    "        self.create_features()\n",
    "        \n",
    "        return self.get_train(), self.get_test()\n",
    "    \n",
    "    def round_values(self):\n",
    "        self.train = np.around(self.train, decimals=1)\n",
    "        self.test  = np.around(self.test, decimals=1)\n",
    "    \n",
    "    def create_features(self):\n",
    "        # feature based out of f1\n",
    "        self.train['f1_cat'] = (self.train['f1'] < 140).astype(np.int)\n",
    "        self.test['f1_cat']  = (self.test['f1'] < 140).astype(np.int)\n",
    "        \n",
    "        # feature based out of f9\n",
    "        self.train['f9_cat'] = (self.train['f9'] < 140).astype(np.int)\n",
    "        self.test['f9_cat']  = (self.test['f9'] < 140).astype(np.int)\n",
    "        \n",
    "        # feature based out of 10\n",
    "        self.train['f10_cat'] = (self.train['f10'] < 140).astype(np.int)\n",
    "        self.test['f10_cat']  = (self.test['f10'] < 140).astype(np.int)\n",
    "        \n",
    "        # feature out of f14\n",
    "        self.train['f14_cat'] = (self.train['f14'] == 0.0).astype(np.int)\n",
    "        self.test['f14_cat']  = (self.test['f14'] == 0.0).astype(np.int)\n",
    "        \n",
    "        # feature out of f6\n",
    "        self.train['f6_cat'] = (self.train['f6'] < 2e4).astype(np.int)\n",
    "        self.test['f6_cat']  = (self.test['f6'] < 2e4).astype(np.int)\n",
    "         \n",
    "    def get_train(self):\n",
    "        return self.train\n",
    "    \n",
    "    def get_test(self):\n",
    "        return self.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat = FeatureExtractor(train[train.columns[:12]], test[test.columns[:12]])\n",
    "train_sub, test_sub = feat.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sub.to_csv(os.path.join(basepath, 'data/processed/train_sub.csv'), index=False)\n",
    "test_sub.to_csv(os.path.join(basepath, 'data/processed/test_sub.csv'), index=False)\n",
    "\n",
    "train[['loss']].to_csv(os.path.join(basepath, 'data/processed/target.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
